ğŸ“Š PrÃ©diction des prix automobiles avec Machine Learning

Contexte du projet:

Ce projet vise Ã  prÃ©dire le prix des voitures dâ€™occasion Ã  partir dâ€™un jeu de donnÃ©es riche en caractÃ©ristiques techniques et commerciales (marque, modÃ¨le, type de carburant, boÃ®te de vitesse, etc.).

Lâ€™objectif est dâ€™Ã©valuer la performance de diffÃ©rents modÃ¨les de machine learning, principalement Random Forest et XGBoost, pour estimer le prix avec la meilleure prÃ©cision possible. Une Ã©tape clÃ© consiste Ã  optimiser les hyperparamÃ¨tres via GridSearchCV pour amÃ©liorer la qualitÃ© des prÃ©dictions.

Le jeu de donnÃ©es autoscout.csv contient plusieurs variables explicatives et une cible continue, le prix (price). Le projet suit une dÃ©marche classique de data science : exploration, prÃ©traitement, modÃ©lisation, optimisation et Ã©valuation.

ğŸ§¾ DonnÃ©es utilisÃ©es
Fichier : autoscout.csv
Colonnes principales :

make_model : marque et modÃ¨le

body_type, Fuel, Gearing_Type : caractÃ©ristiques du vÃ©hicule

price : prix cible Ã  prÃ©dire

autres variables techniques et options

ğŸš€ Ã‰tapes du projet
1. Chargement et exploration des donnÃ©es
   Chargement du fichier CSV avec pandas

   Analyse des colonnes, valeurs manquantes, types de donnÃ©es

   Visualisation des variables importantes (ex: rÃ©partition des prix, types de carburant, marques)


2. PrÃ©traitement et encodage
    Gestion des valeurs manquantes

    Encodage des variables catÃ©gorielles avec pd.get_dummies (ex: Fuel, Gearing_Type, make_model)

    SÃ©paration des variables explicatives (features) et cible (price)


3. SÃ©paration des donnÃ©es en train/test
    Utilisation de train_test_split pour crÃ©er des jeux dâ€™entraÃ®nement et de test

    Test = 20% des donnÃ©es 


5. ModÃ©lisation avancÃ©e : Random Forest Regressor et XGBoost

    EntraÃ®nement du modÃ¨le XGBoost sans optimisation

1.Graphique de comparaison des prÃ©dictions (Random Forest vs XGBoost)
Ce graphique montre la corrÃ©lation entre les prix rÃ©els et les prix prÃ©dits par les deux modÃ¨les. Une droite parfaitement diagonale reprÃ©senterait une prÃ©diction idÃ©ale. On observe que les prÃ©dictions de XGBoost sont lÃ©gÃ¨rement plus proches de cette diagonale, indiquant une meilleure qualitÃ© de prÃ©diction.
<img width="1043" height="521" alt="image" src="https://github.com/user-attachments/assets/19ea303b-eb5f-4dea-8abd-68ec51abc6f0" />

RÃ©sultats:

 Random Forest - MSE: 4791923.65, RÂ²: 0.9112

XGBoost - MSE: 4449720.50, RÂ²: 0.9175

NB :
MÃªme sans optimisation avancÃ©e, XGBoost montre une robustesse et une efficacitÃ© impressionnantes. 
Ce rÃ©sultat dÃ©montre quâ€™il constitue une solution solide pour la prÃ©diction des prix de voitures, mÃªme en configuration standard.
Ã‰valuation sur test avec MSE et RÂ²
<img width="840" height="487" alt="image" src="https://github.com/user-attachments/assets/540bee53-8284-4f3c-9d30-db6b2594475f" />
<img width="817" height="485" alt="image" src="https://github.com/user-attachments/assets/50d1d51c-6b47-42a6-a06e-9aa41b02f047" />

NB:
Graphiques des erreurs (MSE) et qualitÃ© de prÃ©diction (RÂ²) avant optimisation
Ces trois graphiques comparent quantitativement les performances des modÃ¨les sans optimisation.
Le MSE plus faible de XGBoost montre quâ€™il fait moins dâ€™erreurs quadratiques moyennes.
Le RÂ² plus Ã©levÃ© indique que XGBoost explique une plus grande partie de la variance du prix.

6. Optimisation des hyperparamÃ¨tres avec GridSearchCV
DÃ©finition dâ€™une grille dâ€™hyperparamÃ¨tres (n_estimators, max_depth, learning_rate)

Recherche via validation croisÃ©e (3-fold)

SÃ©lection des meilleurs paramÃ¨tres

RÃ©entraÃ®nement du modÃ¨le avec ces paramÃ¨tres

Nouvelle Ã©valuation

Meilleurs paramÃ¨tres trouvÃ©s :
{'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 150}

Performances amÃ©liorÃ©es :
MSE: 4,146,879.0
RÂ²: 0.9232

7. Visualisation des rÃ©sultats

NB: Graphiques comparatifs des performances avant et aprÃ¨s GridSearchCV

Le graphique RÂ² montre une augmentation de la capacitÃ© explicative du modÃ¨le XGBoost aprÃ¨s optimisation des hyperparamÃ¨tres.

Le graphique MSE confirme la rÃ©duction de lâ€™erreur quadratique moyenne, signe dâ€™une meilleure prÃ©cision prÃ©dictive.

Ces visualisations illustrent clairement lâ€™intÃ©rÃªt dâ€™un tuning mÃ©thodique des hyperparamÃ¨tres pour maximiser la performance dâ€™un modÃ¨le de machine learning.

Graphique comparatif RÂ² avant/aprÃ¨s GridSearchCV
<img width="735" height="437" alt="image" src="https://github.com/user-attachments/assets/8053ae5d-48f9-4be0-bfc6-82ebac39f594" />

Graphique comparatif MSE avant/aprÃ¨s GridSearchCV

<img width="699" height="468" alt="image" src="https://github.com/user-attachments/assets/92e97d48-3ca5-40b6-b835-956f3653e9a8" />

RÃ©sultats principaux:

ModÃ¨les testÃ©s : Random Forest Regressor et XGBoost.

MÃ©triques utilisÃ©es : Mean Squared Error (MSE) et coefficient de dÃ©termination (RÂ²).

Performance initiale :
Random Forest : MSE = 4 791 923.65, RÂ² = 0.9112
XGBoost : MSE = 4 449 720.50, RÂ² = 0.9175

Optimisation des hyperparamÃ¨tres avec GridSearchCV sur XGBoost :
Meilleurs paramÃ¨tres : learning_rate=0.2, max_depth=5, n_estimators=150
Performance optimisÃ©e : MSE = 4 146 879.0, RÂ² = 0.9232

Lâ€™optimisation des hyperparamÃ¨tres amÃ©liore significativement la prÃ©cision, confirmant lâ€™intÃ©rÃªt de ce type dâ€™approche pour les modÃ¨les complexes.

ğŸ“Œ Remarques
Le projet montre lâ€™importance de lâ€™optimisation des hyperparamÃ¨tres pour amÃ©liorer la qualitÃ© des prÃ©dictions

XGBoost avec GridSearchCV donne les meilleurs rÃ©sultats sur ce dataset

Des amÃ©liorations futures peuvent inclure lâ€™analyse plus fine des variables, nettoyage avancÃ©, ou essais avec dâ€™autres modÃ¨les
