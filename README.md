ğŸ“Š PrÃ©diction des prix automobiles avec Machine Learning
ğŸ¯ Objectif
Analyser les donnÃ©es automobiles (prix, caractÃ©ristiques techniques) pour prÃ©dire le prix des voitures dâ€™occasion en utilisant plusieurs modÃ¨les de machine learning et amÃ©liorer la prÃ©cision par optimisation des hyperparamÃ¨tres.

ğŸ§¾ DonnÃ©es utilisÃ©es
Fichier : autoscout.csv
Colonnes principales :

make_model : marque et modÃ¨le

body_type, Fuel, Gearing_Type : caractÃ©ristiques du vÃ©hicule

price : prix cible Ã  prÃ©dire

autres variables techniques et options

ğŸš€ Ã‰tapes du projet
1. Chargement et exploration des donnÃ©es
Chargement du fichier CSV avec pandas

Analyse des colonnes, valeurs manquantes, types de donnÃ©es

Visualisation des variables importantes (ex: rÃ©partition des prix, types de carburant, marques)


2. PrÃ©traitement et encodage
Gestion des valeurs manquantes

Encodage des variables catÃ©gorielles avec pd.get_dummies (ex: Fuel, Gearing_Type, make_model)

SÃ©paration des variables explicatives (features) et cible (price)


3. SÃ©paration des donnÃ©es en train/test
Utilisation de train_test_split pour crÃ©er des jeux dâ€™entraÃ®nement et de test

Test = 20% des donnÃ©es 


5. ModÃ©lisation avancÃ©e : Random Forest Regressor et XGBoost

EntraÃ®nement du modÃ¨le XGBoost sans optimisation
la figure ci-dessous nous montre la prediction entre le deux modeles

<img width="1043" height="521" alt="image" src="https://github.com/user-attachments/assets/19ea303b-eb5f-4dea-8abd-68ec51abc6f0" />

RÃ©sultats:

Random Forest - MSE: 4791923.65, RÂ²: 0.9112

XGBoost - MSE: 4449720.50, RÂ²: 0.9175
<img width="840" height="487" alt="image" src="https://github.com/user-attachments/assets/2fd41f7d-ecfd-4861-ae0d-5d643e49dd6e" />

NB :
MÃªme sans optimisation avancÃ©e, XGBoost montre une robustesse et une efficacitÃ© impressionnantes. 
Ce rÃ©sultat dÃ©montre quâ€™il constitue une solution solide pour la prÃ©diction des prix de voitures, mÃªme en configuration standard.
Ã‰valuation sur test avec MSE et RÂ²
<img width="840" height="487" alt="image" src="https://github.com/user-attachments/assets/540bee53-8284-4f3c-9d30-db6b2594475f" />
<img width="817" height="485" alt="image" src="https://github.com/user-attachments/assets/50d1d51c-6b47-42a6-a06e-9aa41b02f047" />

6. Optimisation des hyperparamÃ¨tres avec GridSearchCV
DÃ©finition dâ€™une grille dâ€™hyperparamÃ¨tres (n_estimators, max_depth, learning_rate)

Recherche via validation croisÃ©e (3-fold)

SÃ©lection des meilleurs paramÃ¨tres

RÃ©entraÃ®nement du modÃ¨le avec ces paramÃ¨tres

Nouvelle Ã©valuation

Meilleurs paramÃ¨tres trouvÃ©s :
{'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 150}

Performances amÃ©liorÃ©es :
MSE: 4,146,879.0
RÂ²: 0.9232

7. Visualisation des rÃ©sultats
Graphique comparatif RÂ² avant/aprÃ¨s GridSearchCV
<img width="735" height="437" alt="image" src="https://github.com/user-attachments/assets/8053ae5d-48f9-4be0-bfc6-82ebac39f594" />

Graphique comparatif MSE avant/aprÃ¨s GridSearchCV

<img width="699" height="468" alt="image" src="https://github.com/user-attachments/assets/92e97d48-3ca5-40b6-b835-956f3653e9a8" />



ğŸ“Œ Remarques
Le projet montre lâ€™importance de lâ€™optimisation des hyperparamÃ¨tres pour amÃ©liorer la qualitÃ© des prÃ©dictions

XGBoost avec GridSearchCV donne les meilleurs rÃ©sultats sur ce dataset

Des amÃ©liorations futures peuvent inclure lâ€™analyse plus fine des variables, nettoyage avancÃ©, ou essais avec dâ€™autres modÃ¨les
